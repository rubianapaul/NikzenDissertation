{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASHEVILLE AIRBNB SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The purpose of this report is **to analyze customer reviews for Airbnb on Asheville, North Carolina, United States**. And act as a stepping stone **to know what the customers think of the service offered by Asheville's Airbnb, and this analysis could help to know if the hosts are providing good customer service or not**. The analysis progress would be separated on several notebook, and will cover from *data preprocessing, text preprocessing, topic modelling, visualization, model building, to model testing*. \n",
    "\n",
    "> This notebook specifically will only cover the **TEXT PREPROCESSING** and **TOPIC MODELLING** part.\n",
    "\n",
    "> The dataset contains the **detailed review data for listings in Asheville, North Carolina** compiled on **08 November, 2020**. The data are from the **Inside Airbnb site**, it is sourced from publicly available information, from the Airbnb site. The data has been analyzed, cleansed and aggregated where appropriate to faciliate public discussion. More on this data, and other similar data refers to this [link](http://insideairbnb.com/get-the-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# data visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# text processing\n",
    "\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# filter warning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/lizab/halew-reviews-clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198480</td>\n",
       "      <td>87255046.0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>40872502</td>\n",
       "      <td>Nour</td>\n",
       "      <td>Belle appartement rÃ©cent situÃ© Ã  15 minutes...</td>\n",
       "      <td>belle appartement r cent situ minutes pied du ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198480</td>\n",
       "      <td>91814194.0</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>40494412</td>\n",
       "      <td>Vitor</td>\n",
       "      <td>Morada excelente, com limpeza Ã³tima, muito be...</td>\n",
       "      <td>morada excelente com limpeza tima muito bem lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198480</td>\n",
       "      <td>94780243.0</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>70116792</td>\n",
       "      <td>Ricardo</td>\n",
       "      <td>Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....</td>\n",
       "      <td>boa localiza casa c moda e simp tica propriet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198480</td>\n",
       "      <td>96934467.0</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>72247207</td>\n",
       "      <td>Victor</td>\n",
       "      <td>En fin ganska nybyggd lÃ¤genhet med  all utrus...</td>\n",
       "      <td>en fin ganska nybyggd l genhet med utrustning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198480</td>\n",
       "      <td>111434378.0</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>96738915</td>\n",
       "      <td>Elbert Takeshi</td>\n",
       "      <td>Ã“timo apartamento, mtu aconchegante e espaÃ§o...</td>\n",
       "      <td>timo apartamento mtu aconchegante e espa oso g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id           id        date  reviewer_id   reviewer_name  \\\n",
       "0      198480   87255046.0  2016-07-19     40872502            Nour   \n",
       "1      198480   91814194.0  2016-08-06     40494412           Vitor   \n",
       "2      198480   94780243.0  2016-08-17     70116792         Ricardo   \n",
       "3      198480   96934467.0  2016-08-25     72247207          Victor   \n",
       "4      198480  111434378.0  2016-10-31     96738915  Elbert Takeshi   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Belle appartement rÃ©cent situÃ© Ã  15 minutes...   \n",
       "1  Morada excelente, com limpeza Ã³tima, muito be...   \n",
       "2  Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....   \n",
       "3  En fin ganska nybyggd lÃ¤genhet med  all utrus...   \n",
       "4  Ã“timo apartamento, mtu aconchegante e espaÃ§o...   \n",
       "\n",
       "                                    comments_cleaned  \n",
       "0  belle appartement r cent situ minutes pied du ...  \n",
       "1  morada excelente com limpeza tima muito bem lo...  \n",
       "2  boa localiza casa c moda e simp tica propriet ...  \n",
       "3  en fin ganska nybyggd l genhet med utrustning ...  \n",
       "4  timo apartamento mtu aconchegante e espa oso g...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   listing_id        499 non-null    int64  \n",
      " 1   id                499 non-null    float64\n",
      " 2   date              499 non-null    object \n",
      " 3   reviewer_id       499 non-null    int64  \n",
      " 4   reviewer_name     499 non-null    object \n",
      " 5   comments          499 non-null    object \n",
      " 6   comments_cleaned  498 non-null    object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 27.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# check info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check data summary\n",
    "\n",
    "def summary(df):\n",
    "    \n",
    "    columns = df.columns.to_list()\n",
    "    \n",
    "    dtypes = []\n",
    "    unique_counts = []\n",
    "    missing_counts = []\n",
    "    missing_percentages = []\n",
    "    total_counts = [df.shape[0]] * len(columns)\n",
    "\n",
    "    for col in columns:\n",
    "        dtype = str(df[col].dtype)\n",
    "        dtypes.append(dtype)\n",
    "        unique_count = df[col].nunique()\n",
    "        unique_counts.append(unique_count)\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_counts.append(missing_count)\n",
    "        missing_percentage = round((missing_count/df.shape[0]) * 100, 2)\n",
    "        missing_percentages.append(missing_percentage)\n",
    "\n",
    "    df_summary = pd.DataFrame({\n",
    "        \"column\": columns,\n",
    "        \"dtypes\": dtypes,\n",
    "        \"unique_count\": unique_counts,\n",
    "        \"missing_values\": missing_counts,\n",
    "        \"missing_percentage\": missing_percentages,\n",
    "        \"total_count\": total_counts,\n",
    "    })\n",
    "\n",
    "    return df_summary.sort_values(by=\"missing_percentage\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comments_cleaned</td>\n",
       "      <td>object</td>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id</td>\n",
       "      <td>float64</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviewer_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviewer_name</td>\n",
       "      <td>object</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comments</td>\n",
       "      <td>object</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column   dtypes  unique_count  missing_values  \\\n",
       "0  comments_cleaned   object           496               1   \n",
       "1        listing_id    int64             7               0   \n",
       "2                id  float64           499               0   \n",
       "3              date   object           459               0   \n",
       "4       reviewer_id    int64           495               0   \n",
       "5     reviewer_name   object           420               0   \n",
       "6          comments   object           499               0   \n",
       "\n",
       "   missing_percentage  total_count  \n",
       "0                 0.2          499  \n",
       "1                 0.0          499  \n",
       "2                 0.0          499  \n",
       "3                 0.0          499  \n",
       "4                 0.0          499  \n",
       "5                 0.0          499  \n",
       "6                 0.0          499  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check summary\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although these have been fixed on the previous process, seems that there are some `dtypes` that are not proper, there are also a missing values on *comments_clean* feature. Therefore once again I'll clean the data on preprocessing first before going on text cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>393699</td>\n",
       "      <td>16277694.0</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>12313219</td>\n",
       "      <td>Timur</td>\n",
       "      <td>ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾! ÐžÑ‡ÐµÐ½ÑŒ ÑƒÐ´Ð¾...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    listing_id          id        date  reviewer_id reviewer_name  \\\n",
       "69      393699  16277694.0  2014-07-24     12313219         Timur   \n",
       "\n",
       "                                             comments comments_cleaned  \n",
       "69  ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾! ÐžÑ‡ÐµÐ½ÑŒ ÑƒÐ´Ð¾...              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the missing values\n",
    "\n",
    "df[df['comments_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It seems the missing values are caused by the other language or improper commentaries as shown above, therefore I'll fill these values as *No Description* instead and move to clean the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "\n",
    "df['comments_cleaned'] = df['comments_cleaned'].fillna('No Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing columns dtpes\n",
    "\n",
    "for i in df.columns:\n",
    "    if i == 'listing_id' or i == 'id' or i == 'reviewer_id':\n",
    "        df[i] = df[i].astype(np.object)\n",
    "    elif i == 'date' :\n",
    "        df[i] = pd.to_datetime(df[i])\n",
    "    else : \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percentage</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>object</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>object</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reviewer_id</td>\n",
       "      <td>object</td>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reviewer_name</td>\n",
       "      <td>object</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comments</td>\n",
       "      <td>object</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comments_cleaned</td>\n",
       "      <td>object</td>\n",
       "      <td>497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column          dtypes  unique_count  missing_values  \\\n",
       "0        listing_id          object             7               0   \n",
       "1                id          object           499               0   \n",
       "2              date  datetime64[ns]           459               0   \n",
       "3       reviewer_id          object           495               0   \n",
       "4     reviewer_name          object           420               0   \n",
       "5          comments          object           499               0   \n",
       "6  comments_cleaned          object           497               0   \n",
       "\n",
       "   missing_percentage  total_count  \n",
       "0                 0.0          499  \n",
       "1                 0.0          499  \n",
       "2                 0.0          499  \n",
       "3                 0.0          499  \n",
       "4                 0.0          499  \n",
       "5                 0.0          499  \n",
       "6                 0.0          499  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check summary\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It seems that everything's on set. I'll move to the text processing to later do the text modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For this part, I'll lemmatize the text on the *comments_clean* feature to get the tokenized result for modelling part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacymodel for lemmatization\n",
    "\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lemmatize text\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
    "    output = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text) \n",
    "        output.append(' '.join([word.lemma_ for word in doc if word.pos_ in allowed_postags ]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lemmatization\n",
    "\n",
    "comment_list = df['comments_cleaned'].tolist()\n",
    "comment_tokenized = lemmatization(comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appartement r cent situ minute tro minute bus durant\n"
     ]
    }
   ],
   "source": [
    "# check lemmatized comment\n",
    "\n",
    "print(comment_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to store tokenized text\n",
    "\n",
    "df['comments_tokenized'] = comment_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198480</td>\n",
       "      <td>87255046.0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>40872502</td>\n",
       "      <td>Nour</td>\n",
       "      <td>Belle appartement rÃ©cent situÃ© Ã  15 minutes...</td>\n",
       "      <td>belle appartement r cent situ minutes pied du ...</td>\n",
       "      <td>appartement r cent situ minute tro minute bus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198480</td>\n",
       "      <td>91814194.0</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>40494412</td>\n",
       "      <td>Vitor</td>\n",
       "      <td>Morada excelente, com limpeza Ã³tima, muito be...</td>\n",
       "      <td>morada excelente com limpeza tima muito bem lo...</td>\n",
       "      <td>excelente com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198480</td>\n",
       "      <td>94780243.0</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>70116792</td>\n",
       "      <td>Ricardo</td>\n",
       "      <td>Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....</td>\n",
       "      <td>boa localiza casa c moda e simp tica propriet ...</td>\n",
       "      <td>recomendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198480</td>\n",
       "      <td>96934467.0</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>72247207</td>\n",
       "      <td>Victor</td>\n",
       "      <td>En fin ganska nybyggd lÃ¤genhet med  all utrus...</td>\n",
       "      <td>en fin ganska nybyggd l genhet med utrustning ...</td>\n",
       "      <td>med man beh inte all detta boende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198480</td>\n",
       "      <td>111434378.0</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>96738915</td>\n",
       "      <td>Elbert Takeshi</td>\n",
       "      <td>Ã“timo apartamento, mtu aconchegante e espaÃ§o...</td>\n",
       "      <td>timo apartamento mtu aconchegante e espa oso g...</td>\n",
       "      <td>com hospedado lugar era</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id           id       date reviewer_id   reviewer_name  \\\n",
       "0     198480   87255046.0 2016-07-19    40872502            Nour   \n",
       "1     198480   91814194.0 2016-08-06    40494412           Vitor   \n",
       "2     198480   94780243.0 2016-08-17    70116792         Ricardo   \n",
       "3     198480   96934467.0 2016-08-25    72247207          Victor   \n",
       "4     198480  111434378.0 2016-10-31    96738915  Elbert Takeshi   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Belle appartement rÃ©cent situÃ© Ã  15 minutes...   \n",
       "1  Morada excelente, com limpeza Ã³tima, muito be...   \n",
       "2  Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....   \n",
       "3  En fin ganska nybyggd lÃ¤genhet med  all utrus...   \n",
       "4  Ã“timo apartamento, mtu aconchegante e espaÃ§o...   \n",
       "\n",
       "                                    comments_cleaned  \\\n",
       "0  belle appartement r cent situ minutes pied du ...   \n",
       "1  morada excelente com limpeza tima muito bem lo...   \n",
       "2  boa localiza casa c moda e simp tica propriet ...   \n",
       "3  en fin ganska nybyggd l genhet med utrustning ...   \n",
       "4  timo apartamento mtu aconchegante e espa oso g...   \n",
       "\n",
       "                                  comments_tokenized  \n",
       "0  appartement r cent situ minute tro minute bus ...  \n",
       "1                                      excelente com  \n",
       "2                                          recomendo  \n",
       "3                  med man beh inte all detta boende  \n",
       "4                            com hospedado lugar era  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT ANALYSIS - VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, I'll start to analyze the sentiment using **VADER ( Valence Aware Dictionary for Sentiment Reasoning)**. It is basically a model used for text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. VADER relies on a dictionary that maps lexical features to emotion intensities known as sentiment scores. The sentiment score of a text can be obtained by summing up the intensity of each word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assign sentiment class based on compound score\n",
    "\n",
    "def sentiment(comp):\n",
    "    if comp >= 0.05:\n",
    "        return 'positive'\n",
    "    elif (comp > -0.05) and (comp < 0.05):\n",
    "        return 'neutral'\n",
    "    elif comp <= -0.05 :\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sentiment analyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# calculate compound score\n",
    "\n",
    "compound_score = []\n",
    "for i in df['comments_tokenized']:\n",
    "    compound_score.append(analyzer.polarity_scores(i)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to store compound score\n",
    "\n",
    "df['compound_score'] = compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check sentiment on first data\n",
    "\n",
    "sentiment(df['compound_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sentiment based on compound score\n",
    "\n",
    "sent = []\n",
    "for i in range(0, len(df)):\n",
    "    sent.append(sentiment(df['compound_score'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to store sentiment\n",
    "\n",
    "df['sentiment'] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198480</td>\n",
       "      <td>87255046.0</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>40872502</td>\n",
       "      <td>Nour</td>\n",
       "      <td>Belle appartement rÃ©cent situÃ© Ã  15 minutes...</td>\n",
       "      <td>belle appartement r cent situ minutes pied du ...</td>\n",
       "      <td>appartement r cent situ minute tro minute bus ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198480</td>\n",
       "      <td>91814194.0</td>\n",
       "      <td>2016-08-06</td>\n",
       "      <td>40494412</td>\n",
       "      <td>Vitor</td>\n",
       "      <td>Morada excelente, com limpeza Ã³tima, muito be...</td>\n",
       "      <td>morada excelente com limpeza tima muito bem lo...</td>\n",
       "      <td>excelente com</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198480</td>\n",
       "      <td>94780243.0</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>70116792</td>\n",
       "      <td>Ricardo</td>\n",
       "      <td>Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....</td>\n",
       "      <td>boa localiza casa c moda e simp tica propriet ...</td>\n",
       "      <td>recomendo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198480</td>\n",
       "      <td>96934467.0</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>72247207</td>\n",
       "      <td>Victor</td>\n",
       "      <td>En fin ganska nybyggd lÃ¤genhet med  all utrus...</td>\n",
       "      <td>en fin ganska nybyggd l genhet med utrustning ...</td>\n",
       "      <td>med man beh inte all detta boende</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198480</td>\n",
       "      <td>111434378.0</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>96738915</td>\n",
       "      <td>Elbert Takeshi</td>\n",
       "      <td>Ã“timo apartamento, mtu aconchegante e espaÃ§o...</td>\n",
       "      <td>timo apartamento mtu aconchegante e espa oso g...</td>\n",
       "      <td>com hospedado lugar era</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id           id       date reviewer_id   reviewer_name  \\\n",
       "0     198480   87255046.0 2016-07-19    40872502            Nour   \n",
       "1     198480   91814194.0 2016-08-06    40494412           Vitor   \n",
       "2     198480   94780243.0 2016-08-17    70116792         Ricardo   \n",
       "3     198480   96934467.0 2016-08-25    72247207          Victor   \n",
       "4     198480  111434378.0 2016-10-31    96738915  Elbert Takeshi   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Belle appartement rÃ©cent situÃ© Ã  15 minutes...   \n",
       "1  Morada excelente, com limpeza Ã³tima, muito be...   \n",
       "2  Boa localizaÃ§Ã£o, casa cÃ´moda e simpÃ¡tica ....   \n",
       "3  En fin ganska nybyggd lÃ¤genhet med  all utrus...   \n",
       "4  Ã“timo apartamento, mtu aconchegante e espaÃ§o...   \n",
       "\n",
       "                                    comments_cleaned  \\\n",
       "0  belle appartement r cent situ minutes pied du ...   \n",
       "1  morada excelente com limpeza tima muito bem lo...   \n",
       "2  boa localiza casa c moda e simp tica propriet ...   \n",
       "3  en fin ganska nybyggd l genhet med utrustning ...   \n",
       "4  timo apartamento mtu aconchegante e espa oso g...   \n",
       "\n",
       "                                  comments_tokenized  compound_score sentiment  \n",
       "0  appartement r cent situ minute tro minute bus ...             0.0   neutral  \n",
       "1                                      excelente com             0.0   neutral  \n",
       "2                                          recomendo             0.0   neutral  \n",
       "3                  med man beh inte all detta boende             0.0   neutral  \n",
       "4                            com hospedado lugar era             0.0   neutral  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check final dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we've already got everything we need to do the modelling. First I will do topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOPIC MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Topic Modeling** falls under unsupervised machine learning where the documents are processed to obtain the relative topics. It is a very important concept of the traditional Natural Processing Approach because of its potential to obtain semantic relationship between words in the document clusters. \n",
    "\n",
    "> We will use one of **sklearn's method of topic modeling**, the NMF modeling. The NMF is based on Non-negative Matrix Factorization to implement topic modeling. In the NMF model we will use the tf-idf feature vector to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON NEGATIVE MATRIX FACTORIZATION (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Non-Negative Matrix Factorization** is a statistical method to reduce the dimension of the input corpora. It uses factor analysis method to provide comparatively less weightage to the words with less coherence. NMF produces more coherent topics compared to LDA, and it is by default produces sparse representations. This mean that most of the entries are close to zero and only very few parameters have significant values. This can be used when we strictly require fewer topics. \n",
    "\n",
    "> In sort, **the goal of NMF is to find two non-negative matrices (W, H) whose product approximates the non-negative matrix X**. This factorization can be used for example for dimensionality reduction, source separation or topic extraction. We will be using sklearn’s implementation of NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the text term-document matrix\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "tf_idf = vectorizer.fit_transform(df['comments_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'amazing',\n",
       " 'apartment',\n",
       " 'appartement',\n",
       " 'appartment',\n",
       " 'area',\n",
       " 'arrival',\n",
       " 'available',\n",
       " 'avon',\n",
       " 'bar',\n",
       " 'bathroom',\n",
       " 'beautiful',\n",
       " 'bed',\n",
       " 'bus',\n",
       " 'center',\n",
       " 'central',\n",
       " 'check',\n",
       " 'city',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'comfortable',\n",
       " 'communication',\n",
       " 'day',\n",
       " 'distance',\n",
       " 'easy',\n",
       " 'ellie',\n",
       " 'enough',\n",
       " 'et',\n",
       " 'excellent',\n",
       " 'experience',\n",
       " 'fantastic',\n",
       " 'first',\n",
       " 'flat',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'good',\n",
       " 'great',\n",
       " 'heart',\n",
       " 'helpful',\n",
       " 'home',\n",
       " 'host',\n",
       " 'house',\n",
       " 'information',\n",
       " 'kind',\n",
       " 'kitchen',\n",
       " 'lisboa',\n",
       " 'lisbon',\n",
       " 'little',\n",
       " 'living',\n",
       " 'local',\n",
       " 'location',\n",
       " 'lot',\n",
       " 'lovely',\n",
       " 'main',\n",
       " 'manager',\n",
       " 'many',\n",
       " 'minute',\n",
       " 'much',\n",
       " 'neighborhood',\n",
       " 'neighbourhood',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nous',\n",
       " 'old',\n",
       " 'park',\n",
       " 'part',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'person',\n",
       " 'picture',\n",
       " 'place',\n",
       " 'problem',\n",
       " 'quarti',\n",
       " 'quiet',\n",
       " 'real',\n",
       " 'recommendation',\n",
       " 'restaurant',\n",
       " 'right',\n",
       " 'room',\n",
       " 'shop',\n",
       " 'short',\n",
       " 'small',\n",
       " 'spacious',\n",
       " 'station',\n",
       " 'stay',\n",
       " 'street',\n",
       " 'super',\n",
       " 'thank',\n",
       " 'thing',\n",
       " 'time',\n",
       " 'tip',\n",
       " 'town',\n",
       " 'train',\n",
       " 'trip',\n",
       " 'view',\n",
       " 'walk',\n",
       " 'warm',\n",
       " 'week',\n",
       " 'welcome',\n",
       " 'wonderful']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show feature names\n",
    "\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 5) (5, 100)\n"
     ]
    }
   ],
   "source": [
    "# applying NMF factorization\n",
    "\n",
    "nmf_model = NMF(n_components=5, init='nndsvd', random_state=42)\n",
    "W = nmf_model.fit_transform(tf_idf)\n",
    "H = nmf_model.components_\n",
    "print(W.shape, H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topics\n",
    "\n",
    "get_topics = []\n",
    "for index, topic in enumerate(H):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    get_topics.append(' '.join([feature_names[i] for i in topic.argsort()[-5:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host flat place good nice',\n",
       " 'et quarti avon nous appartement',\n",
       " 'beautiful comfortable ellie lisbon apartment',\n",
       " 'day communication location host great',\n",
       " 'wonderful place clean location perfect']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show topics\n",
    "\n",
    "get_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seems that the first, third, and fifth topic talking about how nice the place and also the host is. The second, and fouth one specifically are talking about the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the topics based on tokenized comments\n",
    "\n",
    "topics = []\n",
    "\n",
    "for i in df['comments_tokenized']:\n",
    "    text_to_vector = vectorizer.transform([i])\n",
    "    prob_score = nmf_model.transform(text_to_vector)\n",
    "    topics.append(get_topics[np.argmax(prob_score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to store the topics\n",
    "\n",
    "df['topics'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198480</td>\n",
       "      <td>113367752.0</td>\n",
       "      <td>2016-11-12</td>\n",
       "      <td>98837232</td>\n",
       "      <td>Aleksandra</td>\n",
       "      <td>It's amazing place to stay for a longer time!!...</td>\n",
       "      <td>amazing place stay longer time br lovely comfo...</td>\n",
       "      <td>amazing place long time comfortable modern gre...</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>positive</td>\n",
       "      <td>area room flat place nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198480</td>\n",
       "      <td>229173000.0</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>111501869</td>\n",
       "      <td>Alberto</td>\n",
       "      <td>Exactly what I needed. I was in Lisbon for wor...</td>\n",
       "      <td>exactly needed lisbon work day home night plac...</td>\n",
       "      <td>lisbon work day home night place less minute r...</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>positive</td>\n",
       "      <td>day lisbon home host good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198480</td>\n",
       "      <td>270488735.0</td>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>20963483</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>The host canceled this reservation 102 days be...</td>\n",
       "      <td>host canceled reservation days arrival automat...</td>\n",
       "      <td>host reservation day arrival posting</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>day lisbon home host good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>393699</td>\n",
       "      <td>1069644.0</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>1974225</td>\n",
       "      <td>Cidalia</td>\n",
       "      <td>We are a family with a 6 year old and normally...</td>\n",
       "      <td>family year old normally book entire apartment...</td>\n",
       "      <td>family year old book entire apartment time dif...</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>positive</td>\n",
       "      <td>thank comfortable ellie lisbon apartment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198480</td>\n",
       "      <td>298408477.0</td>\n",
       "      <td>2018-07-29</td>\n",
       "      <td>85843062</td>\n",
       "      <td>Fabia</td>\n",
       "      <td>It's a very functional and spacious apartment....</td>\n",
       "      <td>functional spacious apartment issues non worki...</td>\n",
       "      <td>functional spacious apartment issue non workin...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>positive</td>\n",
       "      <td>thank comfortable ellie lisbon apartment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id           id       date reviewer_id reviewer_name  \\\n",
       "0     198480  113367752.0 2016-11-12    98837232    Aleksandra   \n",
       "1     198480  229173000.0 2018-01-22   111501869       Alberto   \n",
       "2     198480  270488735.0 2018-05-29    20963483        Carlos   \n",
       "3     393699    1069644.0 2012-04-01     1974225       Cidalia   \n",
       "4     198480  298408477.0 2018-07-29    85843062         Fabia   \n",
       "\n",
       "                                            comments  \\\n",
       "0  It's amazing place to stay for a longer time!!...   \n",
       "1  Exactly what I needed. I was in Lisbon for wor...   \n",
       "2  The host canceled this reservation 102 days be...   \n",
       "3  We are a family with a 6 year old and normally...   \n",
       "4  It's a very functional and spacious apartment....   \n",
       "\n",
       "                                    comments_cleaned  \\\n",
       "0  amazing place stay longer time br lovely comfo...   \n",
       "1  exactly needed lisbon work day home night plac...   \n",
       "2  host canceled reservation days arrival automat...   \n",
       "3  family year old normally book entire apartment...   \n",
       "4  functional spacious apartment issues non worki...   \n",
       "\n",
       "                                  comments_tokenized  compound_score  \\\n",
       "0  amazing place long time comfortable modern gre...          0.9846   \n",
       "1  lisbon work day home night place less minute r...          0.9618   \n",
       "2               host reservation day arrival posting          0.0000   \n",
       "3  family year old book entire apartment time dif...          0.9940   \n",
       "4  functional spacious apartment issue non workin...          0.6369   \n",
       "\n",
       "  sentiment                                    topics  \n",
       "0  positive                 area room flat place nice  \n",
       "1  positive                 day lisbon home host good  \n",
       "2   neutral                 day lisbon home host good  \n",
       "3  positive  thank comfortable ellie lisbon apartment  \n",
       "4  positive  thank comfortable ellie lisbon apartment  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5 data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Belle appartement rÃ©cent situÃ© Ã\\xa0 15 minutes Ã\\xa0 pied du mÃ©tro et Ã\\xa0 5 minutes du bus qui est desservi tout au long de la nuit.<br/>Ana s'est rendu disponible durant le sÃ©jour.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show example on topic 1\n",
    "\n",
    "df['comments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Morada excelente, com limpeza Ã³tima, muito bem localizada, uma regiÃ£o com um espaÃ§o verde muito bom e prÃ³ximo a transportes de qualidade (metro e autocarros)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show example on topic 2\n",
    "\n",
    "df['comments'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En fin ganska nybyggd lÃ¤genhet med  all utrustning man behÃ¶ver. Det Ã¤r inte alls svÃ¥rt att ta sig till stan om det sÃ¥ Ã¤r med tunnelbana buss eller taxi. Kommer att rekommendera detta boende till andra.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show example on topic 5\n",
    "\n",
    "df['comments'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seems that this model is quite right to predict the topics. Now to the next phase, I'll start to dump the cleaned data and build the model using various algorithm on the separate notebook. Although I want to address something first, many of features such as *comments* and *comments_cleaned* are rather giving out some false sentiment and topics. I think just for the sake of modelling, if possible I would rather drop these data later. I'll show it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to new dataframe\n",
    "\n",
    "df.to_csv('halew-reviews-tokenized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [listing_id, id, date, reviewer_id, reviewer_name, comments, comments_cleaned, comments_tokenized, compound_score, sentiment, topics]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the anomaly\n",
    "\n",
    "df[df['comments']=='No Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_tokenized</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>393699</td>\n",
       "      <td>16277694.0</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>12313219</td>\n",
       "      <td>Timur</td>\n",
       "      <td>ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾! ÐžÑ‡ÐµÐ½ÑŒ ÑƒÐ´Ð¾...</td>\n",
       "      <td>No Description</td>\n",
       "      <td>description</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>host flat place good nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id          id       date reviewer_id reviewer_name  \\\n",
       "69     393699  16277694.0 2014-07-24    12313219         Timur   \n",
       "\n",
       "                                             comments comments_cleaned  \\\n",
       "69  ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾! ÐžÑ‡ÐµÐ½ÑŒ ÑƒÐ´Ð¾...   No Description   \n",
       "\n",
       "   comments_tokenized  compound_score sentiment                     topics  \n",
       "69        description             0.0   neutral  host flat place good nice  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the anomaly 2\n",
    "\n",
    "df[df['comments_cleaned']=='No Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "\n",
    ">- https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
    ">- https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
